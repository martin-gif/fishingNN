{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "from dataloader import fishingDataLoader\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:26:02.172055Z",
     "start_time": "2024-04-10T12:25:54.738895Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def emptyLog():\n",
    "    folder = \"logs\"\n",
    "    for f in os.listdir(folder):\n",
    "        os.remove(os.path.join(folder, f))\n",
    "    log_dir = f\"{folder}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True,\n",
    "        write_images=False,\n",
    "        update_freq=\"epoch\",\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:26:03.012292Z",
     "start_time": "2024-04-10T12:26:03.004445Z"
    }
   },
   "id": "adcff4e0462e24f4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#emptyLog()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:26:04.124348Z",
     "start_time": "2024-04-10T12:26:04.118706Z"
    }
   },
   "id": "ff070ed96a9de387"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def loadFishingData():\n",
    "    loader = fishingDataLoader()\n",
    "    data = loader.loadAllTrainingData()\n",
    "    return data.reset_index(drop=True)\n",
    "\n",
    "def loadIresData():\n",
    "    data = pd.read_csv(\"test/iris_original.csv\")\n",
    "    return data\n",
    "\n",
    "def createHotVector(y):\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        if len(lables.columns) == 1: # check if Datafram has only one colum\n",
    "            return -1\n",
    "        \n",
    "        \n",
    "        y_vector = np_utils.to_categorical(y.to_numpy())\n",
    "    else:\n",
    "        y_vector = np_utils.to_categorical(y)\n",
    "    return pd.DataFrame(y_vector)\n",
    "\n",
    "def cleanrows(df: pd.DataFrame):\n",
    "    old_count_rows = df.shape[0]\n",
    "    df = df.dropna()\n",
    "    new_conut_rows = df.shape[0]\n",
    "    print(f\"deletet {old_count_rows-new_conut_rows} rows\")\n",
    "    return df\n",
    "\n",
    "def generateClassWeightsFromHotVektor(lable: pd.DataFrame):\n",
    "    n_samples, n_classes = lable.shape\n",
    "    feature_index, idx, count = tf.unique_with_counts(tf.argmax(lable,axis=1))\n",
    "    class_weight = dict()\n",
    "    \n",
    "    for key, samples_of_class in zip(feature_index.numpy(),count.numpy()):\n",
    "        score = n_samples/(n_classes*samples_of_class)\n",
    "        class_weight[key] = score \n",
    "    return class_weight\n",
    "    \n",
    "\n",
    "def normalizeColums(df: pd.DataFrame, name_of_cols):\n",
    "    df[name_of_cols] = df[name_of_cols]/ df[name_of_cols].abs().max()\n",
    "    return df\n",
    "    \n",
    "def printFeatureDistribution(features):\n",
    "    if features.shape[-1] != 1:\n",
    "        features = tf.argmax(features,axis=1)\n",
    "    \n",
    "    if isinstance(features, pd.DataFrame):\n",
    "        features = features.to_numpy()\n",
    "    feature_index, idx, count = tf.unique_with_counts(features)\n",
    "    feature_index = feature_index.numpy()\n",
    "    count = count.numpy()\n",
    "    percent = tf.round((count/ sum(count))*10000)/100\n",
    "    d = {\n",
    "        \"amount\": count,\n",
    "        \"percent %\": percent\n",
    "    }\n",
    "    dist = pd.DataFrame(d, index=feature_index)\n",
    "    print(dist)\n",
    "    \n",
    "def prepareDataset(raw_data: pd.DataFrame, testSize = 0.2):\n",
    "    \n",
    "    raw_data = cleanrows(raw_data) #Del row with nan values\n",
    "    \n",
    "    nameOfFeatureCols = raw_data.columns[:-1]\n",
    "    number_coloums = len(raw_data.columns)\n",
    "    nameOfTargetCol = raw_data.columns[-1]\n",
    "    raw_data = pd.get_dummies(raw_data, columns=[nameOfTargetCol], dtype=float)\n",
    "    \n",
    "    target_colums = len(raw_data.columns)-number_coloums+1 # how many target coloums exists\n",
    "    \n",
    "    train_data, val_data = train_test_split(raw_data, test_size=testSize)\n",
    "    \n",
    "    train_features, train_lable = train_data.iloc[:,:-target_colums], train_data.iloc[:,-target_colums:]\n",
    "    val_features, val_lable = val_data.iloc[:,:-target_colums], val_data.iloc[:,-target_colums:]\n",
    "    \n",
    "\n",
    "    return train_features, train_lable, val_features, val_lable\n",
    "\n",
    "def turnUnixTimeToDate(date: int):\n",
    "    return datetime.datetime.utcfromtimestamp(date).strftime('%Y-%m-%d %H:%M:%S')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:26:05.095677Z",
     "start_time": "2024-04-10T12:26:05.091996Z"
    }
   },
   "id": "8fc162a1a27a1970"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 mmsi     timestamp  distance_from_shore  distance_from_port  \\\n",
      "0        1.252340e+12  1.325376e+09             0.000000             0.00000   \n",
      "1        1.252340e+12  1.325378e+09             0.000000             0.00000   \n",
      "2        1.252340e+12  1.325379e+09             0.000000             0.00000   \n",
      "3        1.252340e+12  1.325380e+09             0.000000             0.00000   \n",
      "4        1.252340e+12  1.325381e+09             0.000000             0.00000   \n",
      "...               ...           ...                  ...                 ...   \n",
      "1545318  4.393595e+13  1.480030e+09        132057.359375        507208.40625   \n",
      "1545319  4.393595e+13  1.480030e+09        132057.359375        507208.40625   \n",
      "1545320  4.393595e+13  1.480030e+09        132057.359375        507208.40625   \n",
      "1545321  4.393595e+13  1.480030e+09        132057.359375        507208.40625   \n",
      "1545322  4.393595e+13  1.480030e+09        132030.843750        506601.81250   \n",
      "\n",
      "         speed      course        lat         lon  is_fishing  labels  \n",
      "0          0.0  153.000000  52.458649    4.581200        -1.0       0  \n",
      "1          0.0  153.000000  52.458668    4.581167        -1.0       0  \n",
      "2          0.0  153.000000  52.458633    4.581183        -1.0       0  \n",
      "3          0.0  153.000000  52.458649    4.581234        -1.0       0  \n",
      "4          0.0  153.000000  52.458649    4.581183        -1.0       0  \n",
      "...        ...         ...        ...         ...         ...     ...  \n",
      "1545318   13.1  199.800003   1.138018  153.583633        -1.0       6  \n",
      "1545319   12.8  199.800003   1.135133  153.582855        -1.0       6  \n",
      "1545320   12.9  196.800003   1.134502  153.582626        -1.0       6  \n",
      "1545321   13.0  198.899994   1.131033  153.581512        -1.0       6  \n",
      "1545322   12.8  197.300003   1.129303  153.580948        -1.0       6  \n",
      "\n",
      "[21769846 rows x 10 columns]\n",
      "deletet 183 rows\n"
     ]
    }
   ],
   "source": [
    "#raw_data = loadFishingData()\n",
    "\n",
    "train_features, train_lables, val_features, val_lables = prepareDataset(loadFishingData(),testSize=0.2)\n",
    "\n",
    "\n",
    "TARGETS = len(train_lables.columns)\n",
    "INPUTS = train_features.shape[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:26:33.262024Z",
     "start_time": "2024-04-10T12:26:06.270370Z"
    }
   },
   "id": "64d8baa693c7c933"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loader = fishingDataLoader()\n",
    "print(loader.file_list)\n",
    "loader.genSmalerDataset(sample=60000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.382483Z"
    }
   },
   "id": "6a202ff72506fd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "groups = train_features.groupby('mmsi')\n",
    "print(type(groups))\n",
    "for name,group in groups:\n",
    "    print(name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.384183Z"
    }
   },
   "id": "76a462d9375c336a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_weights = generateClassWeightsFromHotVektor(train_lables)\n",
    "print(class_weights)\n",
    "\n",
    "printFeatureDistribution(train_lables)\n",
    "\n",
    "print(INPUTS, TARGETS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.385997Z"
    }
   },
   "id": "7e66190ebecfa5aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def genModel(output_bias=None):\n",
    "    if output_bias is not  None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    \n",
    "    model = tf.keras.Sequential(\n",
    "        name= \"simpleModel\",\n",
    "        layers = [\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.relu, input_dim=INPUTS, name='dense1'),  # input shape required\n",
    "        tf.keras.layers.Dense(30, activation=tf.nn.relu, name='dense2'),\n",
    "        tf.keras.layers.Dense(TARGETS, activation=tf.nn.softmax, name='dense3', bias_initializer=output_bias)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Recall(name=\"Recall\"),\n",
    "        tf.keras.metrics.Precision(name=\"Precision\"),\n",
    "    ]\n",
    ")\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.387602Z"
    }
   },
   "id": "f4bfb1ec78f892da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Early stop\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.001, patience=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.389271Z"
    }
   },
   "id": "5cd68517352e10e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SimpleModel(tf.keras.Model):\n",
    "    INPUTS = 19\n",
    "    TARGETS = 6\n",
    "\n",
    "    def __init__(self, input_dim = 9 ,output_bias=None):\n",
    "        super(SimpleModel, self).__init__(name='SimpleModel')\n",
    "        if output_bias is not None:\n",
    "            output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "        self.batchNorm = tf.keras.layers.BatchNormalization(name='BatchNormalization')\n",
    "        self.Layer1 = tf.keras.layers.Dense(20, activation=tf.nn.relu,name='dense1')  # input shape required\n",
    "        self.Layer2 = tf.keras.layers.Dense(20, activation=tf.nn.relu, name='dense2')\n",
    "        self.Layer3 = tf.keras.layers.Dense(10, activation=tf.nn.relu, name='dense3')\n",
    "        self.Output = tf.keras.layers.Dense(self.TARGETS, activation=tf.nn.softmax, name='outout',\n",
    "                                            bias_initializer=output_bias)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.batchNorm(inputs)\n",
    "        x = self.Layer1(x)\n",
    "        x = self.Layer2(x)\n",
    "        x = self.Layer3(x)\n",
    "        x = self.Output(x)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.390289Z"
    }
   },
   "id": "56e4b5658072585"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model = genModel()\n",
    "model = SimpleModel()\n",
    "\n",
    "model.build((None,9))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Recall(name=\"Recall\"),\n",
    "        tf.keras.metrics.Precision(name=\"Precision\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.391268Z"
    }
   },
   "id": "cf3cd7bbc43f1a8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = model.evaluate(train_features, train_lables, batch_size=10000)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.392695Z"
    }
   },
   "id": "46375491613927ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "#print(features.iloc[0],lables.iloc[0])\n",
    "\n",
    "history = model.fit(\n",
    "    x = train_features,\n",
    "    y = train_lables,\n",
    "    batch_size=20000,\n",
    "    epochs= 10,\n",
    "    shuffle=True,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    #callbacks= [early_stop_callback],\n",
    "    # class_weight=class_weights,\n",
    "    validation_data=(val_features,val_lables),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.393909Z"
    }
   },
   "id": "82babb35c671be2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2 ,figsize =(15, 7)) \n",
    "\n",
    "for metric in history.history.keys():\n",
    "    if \"loss\" in metric or 'val' not in metric:\n",
    "        continue\n",
    "    data = history.history[metric]\n",
    "    one = data[:-1]\n",
    "    two = data[1:]\n",
    "    ax[0].set_title('development plot')\n",
    "    ax[0].plot(data, label=metric)\n",
    "    ax[1].set_title('change plot')\n",
    "    ax[1].plot(np.array(two)-np.array(one) , label=metric)\n",
    "    \n",
    "#plt.ylim(0, 15)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.394936Z"
    }
   },
   "id": "8526ddb3e18b18ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#evaluation_data = features.iloc[::1000]\n",
    "#evaluation_label = lables.iloc[::1000]\n",
    "\n",
    "amount = 100\n",
    "indize = np.linspace(0,len(val_features)-1, num=amount, dtype=int)\n",
    "\n",
    "evaluation_data = val_features.iloc[indize]\n",
    "evaluation_label = val_lables.iloc[indize]\n",
    "\n",
    "evaluation_predictions = model.predict(evaluation_data)\n",
    "\n",
    "#print(\"Prediction:\\t {}\".format(tf.math.argmax(evaluation_predictions, axis=1)))\n",
    "#print(\"Labels:\\t\\t {}\".format(tf.argmax(evaluation_label.to_numpy(),axis=1)))\n",
    "\n",
    "cunf_matrix = confusion_matrix(tf.argmax(evaluation_label,axis=1),tf.argmax(evaluation_predictions, axis=1))\n",
    "print(cunf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.395973Z"
    }
   },
   "id": "687e93ee19b028c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(train_features.iloc[0][0])\n",
    "vesselForPlot = train_features[train_features[\"mmsi\"]==215151145083937.0].sort_values(by=[\"timestamp\"])\n",
    "print(vesselForPlot.loc[vesselForPlot[\"distance_from_port\"]==0.0])\n",
    "startTime = 0\n",
    "endtime = 10\n",
    "error = 4\n",
    "vesselForPlot = vesselForPlot.iloc[startTime:endtime+1]\n",
    "\n",
    "minLat, maxLat = vesselForPlot[\"lat\"].min()-error,vesselForPlot[\"lat\"].max()+error\n",
    "minLon, maxLon = vesselForPlot[\"lon\"].min()-error,vesselForPlot[\"lon\"].max()+error\n",
    "print(turnUnixTimeToDate(vesselForPlot.iloc[startTime][\"timestamp\"]))\n",
    "print(turnUnixTimeToDate(vesselForPlot.iloc[endtime][\"timestamp\"]))\n",
    " \n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "\n",
    "world.plot(ax=ax)\n",
    "ax.scatter(x=vesselForPlot[\"lat\"],y=vesselForPlot[\"lon\"],s=10,c=\"r\")\n",
    "\n",
    "plt.xlim([minLat, maxLat])\n",
    "plt.ylim([minLon,maxLon])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.396860Z"
    }
   },
   "id": "aec69c43b6f2861f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit\n",
    "\n",
    "print(\"127.0.0.1:6006\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-10T12:25:20.397872Z"
    }
   },
   "id": "7d770e8144ccfa0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
